{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation Metrics\n",
        "\n",
        "We use huggingface `evaluate` library for most of the metrics shown. See documentation here: https://huggingface.co/evaluate-metric\n"
      ],
      "metadata": {
        "id": "7vDQeksAhQcs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAq104f_g8rz"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate sacrebleu rouge_score bert_score unbabel-comet\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See all huggingface metrics here: https://huggingface.co/evaluate-metric"
      ],
      "metadata": {
        "id": "r7hkwDpiirOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLEU"
      ],
      "metadata": {
        "id": "_IVoUk-9W0bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"bleu\")"
      ],
      "metadata": {
        "id": "6qzOrwI1hPAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = \"เขา หาม มเหสี\"\n",
        "target = \"เขา หาม หมา มเหสี\"\n",
        "results = bleu.compute(predictions=[pred], references=[[target]], tokenizer=lambda s: s.split(\" \"))\n",
        "results"
      ],
      "metadata": {
        "id": "NkI5ecLdjpST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChrF"
      ],
      "metadata": {
        "id": "dJWTSTjJW3gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chrf  = evaluate.load(\"chrf\")"
      ],
      "metadata": {
        "id": "HfPsNoVNl9sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = chrf.compute(predictions=[pred], references=[[target]]) # if word_order = 2, it will be chrF++! but need to input tokenizer\n",
        "results"
      ],
      "metadata": {
        "id": "f5UhI94Ymlu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROUGE"
      ],
      "metadata": {
        "id": "otiXXrOQW6mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge  = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "KjnVlXeyrZON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = [\"Summarization is cool\"]\n",
        "references = [[\"Summarization is beneficial and cool\",\"Summarization saves time\"]]\n",
        "\n",
        "results = rouge.compute(predictions=candidates, references=references)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "mbGoF2x1POqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = [\"A fast brown fox leaps over a sleeping dog\"]\n",
        "references = [[\"The quick brown fox jumps over the lazy dog\"]]\n",
        "\n",
        "results = rouge.compute(predictions=candidates, references=references)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "wrvVqYLZbPwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using huggingface evaluate with Thai will not work natively.  \n",
        "--> See https://stackoverflow.com/questions/73963171/rouge-score-metric-for-non-english-arabic-language-is-not-working    \n",
        "\n",
        "--> https://stackoverflow.com/questions/76633871/why-rouge-score-results-are-confusing-for-non-english-languages\n",
        "\n",
        "https://github.com/huggingface/evaluate/issues/108\n",
        "\n",
        "It seems like the rouge_score library that this metric uses filters all non-alphanueric latin characters\n",
        "in `rouge_scorer/tokenize.py` with `text = re.sub(r\"[^a-z0-9]+\", \" \", six.ensure_str(text))`.\n",
        "\n",
        "The RougeScorer accepts a tokenizer keyword argument."
      ],
      "metadata": {
        "id": "6Zozka8ktFjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "pred = \"เขา หาม มเหสี\"\n",
        "target = \"เขา หาม หมา มเหสี\"\n",
        "\n",
        "class MyTokenizer:\n",
        "  def tokenize(s):\n",
        "    return s.split(\" \")\n",
        "r_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], tokenizer=MyTokenizer)\n",
        "results = r_scorer.score(target, pred)\n",
        "results"
      ],
      "metadata": {
        "id": "S0yf5XiJsA8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## METEOR"
      ],
      "metadata": {
        "id": "zxGWghYiW-ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meteor  = evaluate.load(\"meteor\")"
      ],
      "metadata": {
        "id": "vbIzw18srgue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = \"the cat sat on the mat\"\n",
        "target = \"the cat sat on the mat\"\n",
        "results = meteor.compute(predictions=[pred], references=[[target]])\n",
        "results"
      ],
      "metadata": {
        "id": "iYrHgY9GrjT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = \"the cat sat on the mat\"\n",
        "target = \"the cat sat on the big mat\"\n",
        "results = meteor.compute(predictions=[pred], references=[[target]])\n",
        "results"
      ],
      "metadata": {
        "id": "9N2gAMNxIqLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TER"
      ],
      "metadata": {
        "id": "POmhst9XY_zX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ter  = evaluate.load(\"ter\")"
      ],
      "metadata": {
        "id": "ixAK0708ZBZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = \"the cat sat on the mat\"\n",
        "target = \"the cats sat on the mat\"\n",
        "results = ter.compute(predictions=[pred], references=[[target]])\n",
        "results"
      ],
      "metadata": {
        "id": "QbLQff-kZD-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shift word \"sat\""
      ],
      "metadata": {
        "id": "bl5BS0-_Y482"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = \"the cat sat on the mat\"\n",
        "target = \"the cats on the mat sat\"\n",
        "results = ter.compute(predictions=[pred], references=[[target]])\n",
        "results"
      ],
      "metadata": {
        "id": "5FsYsTKyJK41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shift \"on the mat\""
      ],
      "metadata": {
        "id": "cC5tUXraY8fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = \"the cat sat on the mat\"\n",
        "target = \"on the mat the cat sat\"\n",
        "results = ter.compute(predictions=[pred], references=[[target]])\n",
        "results"
      ],
      "metadata": {
        "id": "ez9qUrt9JOlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BertScore"
      ],
      "metadata": {
        "id": "t_5T0h5Oo2cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bertscore = evaluate.load(\"bertscore\")"
      ],
      "metadata": {
        "id": "sW08Zh_Xm9Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original BERTScore paper showed that BERTScore correlates well with human judgment on sentence-level and system-level evaluation, but this depends on the model and language pair selected.\n",
        "\n",
        "Multilingual Bert supported languages: https://github.com/google-research/bert/blob/master/multilingual.md#list-of-languages\n",
        "\n",
        ">The multilingual model supports the following languages. These languages were chosen because they are the top 100 languages with the largest Wikipedias [...]\n",
        ">\n",
        "> The **Multilingual Cased (New)** release contains additionally **Thai** and **Mongolian**, which were not included in the original release.\n",
        "\n",
        "Finally, calculating the BERTScore metric involves downloading the BERT model that is used to compute the score-- the default model for `en`, `roberta-large`, takes over 1.4GB of storage space and downloading it can take a significant amount of time depending on the speed of your internet connection. If this is an issue, choose a smaller model; for instance `distilbert-base-uncased` is 268MB.\n",
        "\n",
        "Using `lang=th` downloads `bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.47.1)`, which should support Thai."
      ],
      "metadata": {
        "id": "uW48vaeIoVWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = \"เขาหามมเหสี\"\n",
        "target = \"เขาหามหมามเหสี\"\n",
        "results = bertscore.compute(predictions=[pred], references=[target], lang=\"th\")\n",
        "results"
      ],
      "metadata": {
        "id": "sBmCXU39nb8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = bertscore.compute(predictions=[\"ชีวิตทุกข์ทรมานจริง\"], references=[\"ชีวิตมันแย่มาก\"], lang=\"th\")\n",
        "results"
      ],
      "metadata": {
        "id": "uvLXnv2-q6ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = bertscore.compute(predictions=[\"รู้สึกสนุกสุดยอด\"], references=[\"ชีวิตมันแย่มาก\"], lang=\"th\")\n",
        "results"
      ],
      "metadata": {
        "id": "6UK6SH1GrCN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMET"
      ],
      "metadata": {
        "id": "9vNR8brTKTn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comet = evaluate.load('comet')"
      ],
      "metadata": {
        "id": "NHAJ3Y3tO24X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMET takes 3 lists of strings as input: sources (a list of source sentences), predictions (a list of candidate translations) and references (a list of reference translations)."
      ],
      "metadata": {
        "id": "ZpHeyECCK1vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = [\"Dem Feuer konnte Einhalt geboten werden\", \"Schulen und Kindergärten wurden eröffnet.\"]\n",
        "hypothesis = [\"The fire could be stopped\", \"Schools and kindergartens were open\"]\n",
        "reference = [\"They were able to control the fire.\", \"Schools and kindergartens opened\"]\n",
        "results = comet.compute(predictions=hypothesis, references=reference, sources=source)\n",
        "results"
      ],
      "metadata": {
        "id": "w5RlfVWCKcqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}